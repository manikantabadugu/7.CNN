{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%matplotlib inline\r\n",
    "%config InlineBackend.figure_format = 'retina'\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "from torchvision import datasets, transforms\r\n",
    "import torchvision.datasets as datasets"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot([12,3,4])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_dir= 'Cat_Dog_data'\r\n",
    "train_transform = transforms.Compose([transforms.RandomRotation(30),\r\n",
    "                                       transforms.RandomResizedCrop(224),\r\n",
    "                                       transforms.RandomHorizontalFlip(),\r\n",
    "                                       transforms.ToTensor(),\r\n",
    "                                       transforms.Normalize([0.5, 0.5, 0.5], \r\n",
    "                                                            [0.5, 0.5, 0.5])])\r\n",
    "test_transform = transforms.Compose([transforms.RandomResizedCrop(224),transforms.ToTensor(),\r\n",
    "                                       transforms.CenterCrop(224),\r\n",
    "                                       transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])])\r\n",
    "train_data= datasets.ImageFolder(data_dir+'/train', transform= train_transform)\r\n",
    "test_data= datasets.ImageFolder(data_dir+'/test', transform= train_transform)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)\r\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=1)\r\n",
    "trainloader"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x24664ad4a60>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "next(iter(trainloader))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[tensor([[[[ 0.4667,  0.4510,  0.5294,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [ 0.4196,  0.4275,  0.4902,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [ 0.3647,  0.4353,  0.4353,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
       " \n",
       "          [[ 0.1451,  0.1294,  0.1765,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [ 0.0980,  0.1059,  0.1686,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [ 0.0431,  0.1137,  0.1137,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
       " \n",
       "          [[ 0.1294,  0.1137,  0.2078,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [ 0.0824,  0.0902,  0.1529,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [ 0.0275,  0.0980,  0.0980,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]]]),\n",
       " tensor([1])]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def imshow(image, ax=None, title=None, normalize=True):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        print(\"hi\")\n",
    "        fig, ax = plt.subplots()\n",
    "        print(\"hi1\")\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    print(\"hello\")\n",
    "    if normalize:\n",
    "        print(\"fuck\")\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        print(\"fuck1\")\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    print(\"fuck2\")\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "# Run this to test your data loaders\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def output_shape(input_size, padding, kernel_size, stride):\n",
    "    output_size = 1 + (input_size + 2*padding - kernel_size)/stride \n",
    "    return output_size"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "output_shape(input_size=224, padding=0, kernel_size=5, stride=1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "220.0"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*53*53, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "#Â optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}